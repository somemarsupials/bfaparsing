# -*- coding: utf-8 -*-

""" Defines a class that represents a token in a syntax tree. Contains
one class, Token. In many ways, tokens behave like strings. However,
tokens contain a number of other methods for inspecting the tokens
beneath them.
"""

from copy import copy

class Token:

    def __init__(self, token_type=None, text='', 
            no_aggregate=[], tags=[]):
        """ Create a new token. Tokens can be initialised with any of a
        type, a text value, other tags and a list of tokens that aren't
        broken down. 
        
        Tokens can have child tokens beneath them; the "value" of a 
        token is either the text in the token or aggregated text of the 
        tokens below it. Token tags are used to indicate the various
        token types that it has - the token type is always included as
        part of the initialisation. This is used when a token is
        produced as part of an "or" - if C := A | B, the resultant C
        token might also be tagged as an A.

        The no_aggregate argument is used to prevent tokens from being
        broken down. For example, if word := letters, you may wish the
        series method to stop breaking words into individual letters.
        This parameter is the default behaviour, which can be 
        overridden for each call to series.

        The token behaves like a string in most respects when using
        Python's 'magic 'methods' to interact with them. Examples 
        include length, iteration and comparison.

        Tokens also host a number of methods for searching through and
        iterating over children with ease.
        """
        self.token_type = token_type
        # compile tag list
        self.tags = set([*tags, token_type])
        self.text = text
        self.children = []
        self.no_aggregate = []
        self.parent = None

    def add(self, child):
        """ Add a child token to this token. Child-parent relations
        indicate the components of a token: e.g. the token 'foo' is made
        up of 'bar' and 'baz'. This is represented by adding these
        tokens as children. The 'value' method will add the text in
        both of these children to represent a 'foo' token.
        
        Non-literal tokens should not have a text parameter but instead 
        rely on the 'value' method to assemble a representative string.

        Returns nothing.
        """
        # prevent the creation of literals with children
        if self.text:
            raise RuntimeError('adding children to a literal')
        self.children.append(child)
        child.parent = self

    def remove(self, token):
        """ Remove a child from the token. The token's id is used as the
        basis of comparison instead of the __eq__ method - this avoids
        removing the wrong token in a case where two tokens represent
        the same string. Returns nothing. 
        """
        # get the ID of the token to be found
        match = id(token)
        # search children by ID
        for child in self.children:
            if id(child) == match:
                self.children.remove(child)
        # ensure that the child does not point to the parent
        child.parent = None

    def tag(self, name):
        """ Append a string to the tag set. """
        self.tags.add(name)

    def has_under(self, tag=None):
        """ If no tag is given, true if the token has any children. 
        Otherwise, true if there is a child beneath the token that has
        the given tag.
        """
        if tag:
            # iterate over children
            for c in self.children:
                if tag in c.tags:
                    return True
            # return false if no matches are found
            return False
        else:
            # otherwise check for the existence of children
            return len(self.children) > 0

    def value(self, with_whitespace=False):
        """ For a literal (i.e. a token with self.text), get the token's 
        text. Otherwise, recursively get the text values of child 
        tokens. Returns a string.
        """
        # tokens with text should not have children
        # do not call __repr__ here - this would be recursive!
        if self.children and self.text:
            raise RuntimeError(
                'token with text and children: %s' % self.token_type
                )
        # delineate tokens with spaces if required
        elif self.children:
            base = ' ' if with_whitespace else ''
            # use recursion to reach the very base of the tree
            return base.join(c.value() for c in self.children)
        return self.text

    def flatten(self):
        """ Where tokens are generated by recursion, compress the 
        children of those tokens into a flat list. For example, a token 
        created by the rule "a := b a | b" might create a token with the 
        structure "a -> b a -> b", where "->" denotes parent-child
        relations. The flatten operation would convert this to a token 
        with children "a -> b b".

        The flattening technically occurs when a child token has the
        same token type as its parent and itself has a child token with
        that type. Flattening is not just applied to the top-level token 
        but to its children.

        Returns a new Token - the old token is not modified.
        """
        tt = self.token_type
        # create a new token with same type
        new = Token(token_type=tt, text=self.text, tags=self.tags, 
            no_aggregate=self.no_aggregate
            )
        # replace children with flattened children
        for c in self.children:
            # for tokens with matching token types
            if c.token_type == tt and c.has_under(tt):
                # add those without children
                if not c.has_under():
                    new.add(copy(c))
                    continue
                # else add the children of the flattened token
                for child in c.flatten().children:
                    new.add(copy(child))
            # otherwise flatten the child
            else:
                new.add(copy(c).flatten())
        return new

    def series(self, no_aggregate=None, as_str=False):
        """ Generate an ordered list of the lowest-level child tokens
        beneath the given token. In general, these should all be literal
        expressions.

        Use the no_aggregate option to specify a list of token types that
        should not be broken up. For example, 'word' made up of repeated
        'alpha' tokens is probably more useful as it is, rather than
        being given as a series of individual letters.

        Use the as_str option to return a list of strings instead of
        tokens.
        """
        if not no_aggregate:
            no_aggregate = self.no_aggregate
        # don't break down if requested
        if any(t in no_aggregate for t in self.tags):
            return [self.value() if as_str else self]
        output = []
        for c in self.children:
            # recursively call for tokens with children
            if c.has_under():
                output.extend(c.series(no_aggregate, as_str))
            # otherwise return the token value
            else:
                output.append(c.value() if as_str else c)
        return output
        
    def find(self, token_type, as_str=False):
        """ Search the root's children for all instances of tokens
        with the given type. Return a list of tokens, or strings if
        as_str is True.
        """
        output = []
        for c in self.children:
            if c.token_type == token_type:
                output.append(c.value() if as_str else c)
            output.extend(c.find(token_type, as_str=as_str))
        return output
    
    def level(self, index, as_str=False):
        """ Return all tokens at the given depth. For example, 0 returns
        the root, 1 returns the roots children, 2 all grand-children and
        so on. Defaults to the root token.
        """
        output = []
        # return the token if the last level has been reached,
        # or if the token is the last in a branch
        if index == 0 or not self.has_under():
            output.append(self.value() if as_str else self)
        # otherwise move the the next-lowest level
        else:
            for c in self.children:
                output.extend(c.level(index - 1, as_str))
        return output
    
    def child(self, index):
        """ Return the nth child. """
        return self.children[index]

    def __getitem__(self, item):
        """ Get the nth letter in a token. """
        return self.value()[item]

    def __eq__(self, other):
        """ Compare the value of the token to a string or token. """
        if isinstance(other, Token):
            return self.value() == other.value()
        return self.value() == other

    def __len__(self):
        """ Return the length of the token value. """
        return len(self.value())

    def __iter__(self):
        """ Iterate over characters in self. """
        return iter(self.value())

    def __bool__(self):
        """ False for empty tokens, i.e. not token_type or text. """
        return bool(self.token_type or self.text)

    def __nonzero__(self):
        """ False for empty tokens, i.e. not token_type or text. """
        return bool(self.token_type or self.text)

    def __repr__(self):
        return 'Token %s (%s)' % (self.token_type, self.value())

